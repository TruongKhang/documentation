

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Quick-Start &mdash; topicmodel-lib 0.3.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="topicmodel-lib 0.3.1 documentation" href="index.html"/>
        <link rel="next" title="Module" href="list_api.html"/>
        <link rel="prev" title="Welcome to topicmodel-lib’s documentation!" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> topicmodel-lib
          

          
          </a>

          
            
            
              <div class="version">
                0.3.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick-Start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#topic-models">Topic models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#large-scale-learning">Large-scale learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-methods-for-lda">Learning methods for LDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="#posterior-inference">Posterior Inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-input-format">Data input format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#corpus">Corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-format">Data Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#install-topicmodel-lib">Install topicmodel-lib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install">Install</a></li>
<li class="toctree-l3"><a class="reference internal" href="#uninstall">Uninstall</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="list_api.html">Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">topicmodel-lib Tutorials</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">topicmodel-lib</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Quick-Start</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/quick_start.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="quick-start">
<h1><a class="toc-backref" href="#id3">Quick-Start</a><a class="headerlink" href="#quick-start" title="Permalink to this headline">¶</a></h1>
<p>A very short introduction into topic models and how to solve them using topicmodel-lib. This document also introduces some basic concepts and conventions.</p>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#quick-start" id="id3">Quick-Start</a><ul>
<li><a class="reference internal" href="#topic-models" id="id4">Topic models</a><ul>
<li><a class="reference internal" href="#large-scale-learning" id="id5">Large-scale learning</a></li>
<li><a class="reference internal" href="#learning-methods-for-lda" id="id6">Learning methods for LDA</a></li>
<li><a class="reference internal" href="#posterior-inference" id="id7">Posterior Inference</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-input-format" id="id8">Data input format</a><ul>
<li><a class="reference internal" href="#corpus" id="id9">Corpus</a></li>
<li><a class="reference internal" href="#data-format" id="id10">Data Format</a></li>
</ul>
</li>
<li><a class="reference internal" href="#install-topicmodel-lib" id="id11">Install topicmodel-lib</a><ul>
<li><a class="reference internal" href="#requirements" id="id12">Requirements</a></li>
<li><a class="reference internal" href="#install" id="id13">Install</a></li>
<li><a class="reference internal" href="#uninstall" id="id14">Uninstall</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="topic-models">
<h2><a class="toc-backref" href="#id4">Topic models</a><a class="headerlink" href="#topic-models" title="Permalink to this headline">¶</a></h2>
<p>Topic models are probabilistic models of document collections that use latent variables to encode recurring patterns of word use (Blei, 2012). Topic modeling algorithms are inference algorithms; they uncover a set of patterns that pervade a collection and represent each document according to how it exhibits them. These patterns tend to be thematically coherent, which is why the models are called “topic models.” Topic models are used for both descriptive tasks, such as to build thematic navigators of large collections of documents, and for predictive tasks, such as to aid document classification. Topic models have been extended and applied in many domains</p>
<p><a class="reference external" href="./LatentDirichletAllocation.rst">Latent Dirichlet Allocation (LDA)</a> is the simplest topic model, LDA is a generative probabilistic model for collections of discrete data such as text corpora.</p>
<div class="section" id="large-scale-learning">
<h3><a class="toc-backref" href="#id5">Large-scale learning</a><a class="headerlink" href="#large-scale-learning" title="Permalink to this headline">¶</a></h3>
<p>Modern data analysis requires computation with massive data. These problems illustrate some of the challenges to modern data analysis. Our data are complex and high-dimensional; we have assumptions to make�from science, intuition, or other data analyses�that involve structures we believe exist in the data but that we cannot directly observe; and finally our data sets are large, possibly even arriving in a never-ending stream. We deploy this library to computing with graphical models that is appropriate for massive data sets, data that might not fit in memory or even be stored locally. This is an efficient tool for learning LDA at large scales</p>
</div>
<div class="section" id="learning-methods-for-lda">
<h3><a class="toc-backref" href="#id6">Learning methods for LDA</a><a class="headerlink" href="#learning-methods-for-lda" title="Permalink to this headline">¶</a></h3>
<p>To learn LDA at large-scale, a good and efficient approach is stochastic inference <a class="footnote-reference" href="#id2" id="id1">[1]</a>. The learning process includes 2 main steps:</p>
<ul class="simple">
<li>Inference for individual document: infer to find out the <strong>local variables</strong>: topic proportion <span class="math">\(\theta\)</span> and topic indices <strong>z</strong> (estimate directly or estimate their distribution <span class="math">\(\gamma\)</span>, <span class="math">\(\phi\)</span> - “variational parameters”)</li>
<li>Update <strong>global variable</strong> in a stochastic way to find out directly topics <span class="math">\(\beta\)</span> (regularized online learning) or its distribution by estimating <span class="math">\(\lambda\)</span> (online, stream). Global variable here maybe <span class="math">\(\beta\)</span> or <span class="math">\(\lambda\)</span> depend on each stochastic methods.</li>
</ul>
<p>Indeed, this phase is as same as training step in machine learning.</p>
</div>
<div class="section" id="posterior-inference">
<h3><a class="toc-backref" href="#id7">Posterior Inference</a><a class="headerlink" href="#posterior-inference" title="Permalink to this headline">¶</a></h3>
<p>Actually, this is the first step in learning phase above, posterior inference is the core step when designing efficient algorithms for learning topic models from large-scale data. It also plays a important role in many tasks, such as understanding individual texts, dimensionality reduction, and prediction</p>
<p>With given model {<span class="math">\(\alpha\)</span>, <span class="math">\(\eta\)</span>, <span class="math">\(\beta\)</span> (or <span class="math">\(\lambda\)</span>)}, we can infer for new document to find out topic proportion <span class="math">\(\theta\)</span> and <strong>z</strong> if necessary.</p>
<p>There exists some inference algorithms such as: Variational Bayesian (VB), Collapsed variational Bayes (CVB), Fast collapsed variational Bayes (CVB0), Collapsed Gibbs sampling (CGS), Frank Wolfe (FW) and Online Maximum a Posterior Estimation (OPE) (refer <a class="reference external" href="./user_guide.rst">user guide</a> document for detail)</p>
</div>
</div>
<div class="section" id="data-input-format">
<h2><a class="toc-backref" href="#id8">Data input format</a><a class="headerlink" href="#data-input-format" title="Permalink to this headline">¶</a></h2>
<div class="section" id="corpus">
<h3><a class="toc-backref" href="#id9">Corpus</a><a class="headerlink" href="#corpus" title="Permalink to this headline">¶</a></h3>
<p>A corpus is a collection of digital documents. This collection is the input to topicmodel-lib from which it will infer the structure of the documents, their topics, topic proportions, etc. The latent structure inferred from the corpus can later be used to assign topics to new documents which were not present in the training corpus. For this reason, we also refer to this collection as the training corpus. No human intervention (such as tagging the documents by hand) is required - the topic classification is unsupervised.</p>
</div>
<div class="section" id="data-format">
<h3><a class="toc-backref" href="#id10">Data Format</a><a class="headerlink" href="#data-format" title="Permalink to this headline">¶</a></h3>
<p>Our framework is support for 3 input format:</p>
<ul>
<li><p class="first">Corpus with raw text format:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">raw_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Human machine interface for lab abc computer applications&quot;</span><span class="p">,</span>
              <span class="s2">&quot;A survey of user opinion of computer system response time&quot;</span><span class="p">,</span>
              <span class="s2">&quot;The EPS user interface management system&quot;</span><span class="p">,</span>
              <span class="s2">&quot;System and human system engineering testing of EPS&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Relation of user perceived response time to error measurement&quot;</span><span class="p">,</span>
              <span class="s2">&quot;The generation of random binary unordered trees&quot;</span><span class="p">,</span>
              <span class="s2">&quot;The intersection graph of paths in trees&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Graph minors IV Widths of trees and well quasi ordering&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Graph minors A survey&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>More detail for format of raw text corpus in a file, see <a class="reference external" href="./user_guide.rst">user guide</a> document</p>
</li>
<li><p class="first">Term-frequency format (tf):</p>
<p>The implementations only support reading data type in LDA. Please refer to the following site for instructions: <a class="reference external" href="http://www.cs.columbia.edu/~blei/lda-c/">http://www.cs.columbia.edu/~blei/lda-c/</a>
Under LDA, the words of each document are assumed exchangeable.  Thus, each document is succinctly represented as a sparse vector of word counts. The data is a file where each line is of the form:</p>
<p><cite>[N] [term_1]:[count] [term_2]:[count] …  [term_N]:[count]</cite></p>
<p>where [N] is the number of unique terms in the document, and the [count] associated with each term is how many times that term appeared in the document.  Note that [term_i] is an integer which indexes the term (index of that term in file vocabulary); it is not a string.</p>
<p>For example, with corpus as raw_corpus above and file vocabulary is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mf">0.</span> <span class="s2">&quot;human&quot;</span>
<span class="mf">1.</span> <span class="s2">&quot;machine&quot;</span>
<span class="mf">2.</span> <span class="s2">&quot;interface&quot;</span>
<span class="mf">3.</span> <span class="s2">&quot;lab&quot;</span>
<span class="mf">4.</span> <span class="s2">&quot;abc&quot;</span>
<span class="mf">5.</span> <span class="s2">&quot;computer&quot;</span>
<span class="mf">6.</span> <span class="s2">&quot;applications&quot;</span>
<span class="mf">7.</span> <span class="s2">&quot;survey&quot;</span>
<span class="mf">8.</span> <span class="s2">&quot;user&quot;</span>
<span class="mf">9.</span> <span class="s2">&quot;opinion&quot;</span>
<span class="mf">10.</span> <span class="s2">&quot;system&quot;</span>
<span class="mf">11.</span> <span class="s2">&quot;response&quot;</span>
<span class="mf">12.</span> <span class="s2">&quot;time&quot;</span>
<span class="mf">13.</span> <span class="s2">&quot;eps&quot;</span>
<span class="mf">14.</span> <span class="s2">&quot;management&quot;</span>
<span class="mf">15.</span> <span class="s2">&quot;engineering&quot;</span>
<span class="mf">16.</span> <span class="s2">&quot;testing&quot;</span>
<span class="mf">17.</span> <span class="s2">&quot;relation&quot;</span>
<span class="mf">18.</span> <span class="s2">&quot;perceived&quot;</span>
<span class="mf">19.</span> <span class="s2">&quot;error&quot;</span>
<span class="mf">20.</span> <span class="s2">&quot;measurement&quot;</span>
<span class="mf">21.</span> <span class="s2">&quot;generation&quot;</span>
<span class="mf">22.</span> <span class="s2">&quot;random&quot;</span>
<span class="mf">23.</span> <span class="s2">&quot;binary&quot;</span>
<span class="mf">24.</span> <span class="s2">&quot;unordered&quot;</span>
<span class="mf">25.</span> <span class="s2">&quot;trees&quot;</span>
<span class="mf">26.</span> <span class="s2">&quot;intersection&quot;</span>
<span class="mf">27.</span> <span class="s2">&quot;graph&quot;</span>
<span class="mf">28.</span> <span class="s2">&quot;paths&quot;</span>
<span class="mf">29.</span> <span class="s2">&quot;minors&quot;</span>
<span class="mf">30.</span> <span class="s2">&quot;widths&quot;</span>
<span class="mf">31.</span> <span class="s2">&quot;quasi&quot;</span>
<span class="mf">32.</span> <span class="s2">&quot;ordering&quot;</span>
</pre></div>
</div>
<p>The tf format of corpus will be:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">7</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span> <span class="mi">1</span><span class="p">:</span><span class="mi">1</span> <span class="mi">2</span><span class="p">:</span><span class="mi">1</span> <span class="mi">3</span><span class="p">:</span><span class="mi">1</span> <span class="mi">4</span><span class="p">:</span><span class="mi">1</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span> <span class="mi">6</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">7</span> <span class="mi">7</span><span class="p">:</span><span class="mi">1</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span> <span class="mi">9</span><span class="p">:</span><span class="mi">1</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span> <span class="mi">10</span><span class="p">:</span><span class="mi">1</span> <span class="mi">11</span><span class="p">:</span><span class="mi">1</span> <span class="mi">12</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">5</span> <span class="mi">13</span><span class="p">:</span><span class="mi">1</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span> <span class="mi">2</span><span class="p">:</span><span class="mi">1</span> <span class="mi">14</span><span class="p">:</span><span class="mi">1</span> <span class="mi">10</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">5</span> <span class="mi">10</span><span class="p">:</span><span class="mi">2</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span> <span class="mi">15</span><span class="p">:</span><span class="mi">1</span> <span class="mi">16</span><span class="p">:</span><span class="mi">1</span> <span class="mi">13</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">7</span> <span class="mi">17</span><span class="p">:</span><span class="mi">1</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span> <span class="mi">18</span><span class="p">:</span><span class="mi">1</span> <span class="mi">11</span><span class="p">:</span><span class="mi">1</span> <span class="mi">12</span><span class="p">:</span><span class="mi">1</span> <span class="mi">19</span><span class="p">:</span><span class="mi">1</span> <span class="mi">20</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">5</span> <span class="mi">21</span><span class="p">:</span><span class="mi">1</span> <span class="mi">22</span><span class="p">:</span><span class="mi">1</span> <span class="mi">23</span><span class="p">:</span><span class="mi">1</span> <span class="mi">24</span><span class="p">:</span><span class="mi">1</span> <span class="mi">25</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">4</span> <span class="mi">26</span><span class="p">:</span><span class="mi">1</span> <span class="mi">27</span><span class="p">:</span><span class="mi">1</span> <span class="mi">28</span><span class="p">:</span><span class="mi">1</span> <span class="mi">25</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">6</span> <span class="mi">27</span><span class="p">:</span><span class="mi">1</span> <span class="mi">29</span><span class="p">:</span><span class="mi">1</span> <span class="mi">30</span><span class="p">:</span><span class="mi">1</span> <span class="mi">25</span><span class="p">:</span><span class="mi">1</span> <span class="mi">31</span><span class="p">:</span><span class="mi">1</span> <span class="mi">32</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">3</span> <span class="mi">27</span><span class="p">:</span><span class="mi">1</span> <span class="mi">29</span><span class="p">:</span><span class="mi">1</span> <span class="mi">7</span><span class="p">:</span><span class="mi">1</span>
</pre></div>
</div>
</li>
<li><p class="first">Term-sequence format (sq):</p>
<p>Each document is represented by a sequence of token as follow</p>
<blockquote>
<div><p><cite>[token_1] [token_2] ….</cite></p>
</div></blockquote>
<p>[token_i] also is index of it in vocabulary file, not a string.
The sq format of corpus above will be:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span>
<span class="mi">7</span> <span class="mi">8</span> <span class="mi">9</span> <span class="mi">5</span> <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span>
<span class="mi">13</span> <span class="mi">8</span> <span class="mi">2</span> <span class="mi">14</span> <span class="mi">10</span>
<span class="mi">10</span> <span class="mi">0</span> <span class="mi">10</span> <span class="mi">15</span> <span class="mi">16</span> <span class="mi">13</span>
<span class="mi">17</span> <span class="mi">8</span> <span class="mi">18</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">19</span> <span class="mi">20</span>
<span class="mi">21</span> <span class="mi">22</span> <span class="mi">23</span> <span class="mi">24</span> <span class="mi">25</span>
<span class="mi">26</span> <span class="mi">27</span> <span class="mi">28</span> <span class="mi">25</span>
<span class="mi">27</span> <span class="mi">29</span> <span class="mi">30</span> <span class="mi">25</span> <span class="mi">31</span> <span class="mi">32</span>
<span class="mi">27</span> <span class="mi">29</span> <span class="mi">7</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="install-topicmodel-lib">
<h2><a class="toc-backref" href="#id11">Install topicmodel-lib</a><a class="headerlink" href="#install-topicmodel-lib" title="Permalink to this headline">¶</a></h2>
<div class="section" id="requirements">
<h3><a class="toc-backref" href="#id12">Requirements</a><a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h3>
<p>Topicmodel-lib requires:</p>
<ul class="simple">
<li>Linux OS (Stable on Ubuntu)</li>
<li>Python version 2 (stable on version 2.7)</li>
<li>Docutils &gt;= 0.3</li>
<li>Numpy &gt;= 1.8</li>
<li>Scipy &gt;= 0.10,</li>
<li>nltk (Natural Language Toolkit)</li>
<li>Cython</li>
</ul>
</div>
<div class="section" id="install">
<h3><a class="toc-backref" href="#id13">Install</a><a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h3>
<p>If you installed successfully all of package above. Next is steps to install topicmodel-lib</p>
<ul>
<li><p class="first">First, build cython file .pyx to file .so which can be used by python</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>.../topicmodel-lib$ python setup.py build_ext --inplace
</pre></div>
</div>
<p>or if you need permission to build:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>.../topicmodel-lib$ sudo python setup.py build_ext --inplace
</pre></div>
</div>
</li>
<li><p class="first">Second, Install library</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>.../topicmodel-lib$ sudo python setup.py install
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="uninstall">
<h3><a class="toc-backref" href="#id14">Uninstall</a><a class="headerlink" href="#uninstall" title="Permalink to this headline">¶</a></h3>
<p>To uninstall library:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>.../topicmodel-lib$ sudo python setup.py install --record files.txt

.../topicmodel-lib$ cat files.txt | xargs sudo rm -rf
</pre></div>
</div>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>M.D. Hoffman, D.M. Blei, C. Wang, and J. Paisley, “Stochastic variational inference,” The Journal of Machine Learning Research, vol. 14, no. 1, pp. 1303�1347, 2013.</td></tr>
</tbody>
</table>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="list_api.html" class="btn btn-neutral float-right" title="Module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Welcome to topicmodel-lib’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, DSLab.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>