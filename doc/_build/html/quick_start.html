

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction &mdash; topicmodel-lib 0.3.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="topicmodel-lib 0.3.1 documentation" href="index.html"/>
        <link rel="next" title="LDA Model" href="lda_model.html"/>
        <link rel="prev" title="Welcome to topicmodel-lib’s documentation!" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> topicmodel-lib
          

          
          </a>

          
            
            
              <div class="version">
                0.3.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting started</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#topic-models">Topic models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#large-scale-learning">Large-scale learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-methods-for-lda">Learning methods for LDA</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#corpus">Corpus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#data-format">Data Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#raw-text">Raw Text</a></li>
<li class="toctree-l3"><a class="reference internal" href="#term-frequency-tf">Term-frequency (tf)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#term-sequence-sq">Term-sequence (sq)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#guide-to-learn-model">Guide to learn model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#data-preparation">Data Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#learning">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#saving-model-display-topics">Saving model, display topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#inference-for-new-documents">Inference for new documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="#example">Example</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lda_model.html">LDA Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/online_vb.html">Online VB</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/online_cvb0.html">Online CVB0</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/online_cgs.html">Online CGS</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/online_fw.html">Online FW</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/online_ope.html">Online OPE</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/streaming_vb.html">Streaming VB</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/streaming_fw.html">Streaming FW</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/streaming_ope.html">Streaming OPE</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/ml_cgs.html">ML-CGS</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/ml_fw.html">ML-FW</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/ml_ope.html">ML-OPE</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">tmlib.datasets</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">topicmodel-lib</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Introduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/quick_start.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>A very short introduction into topic models and how to solve them using topicmodel-lib. This document also introduces some basic concepts and conventions.</p>
<div class="section" id="topic-models">
<h2>Topic models<a class="headerlink" href="#topic-models" title="Permalink to this headline">¶</a></h2>
<p>Topic models are probabilistic models of document collections that use latent variables to encode recurring patterns of word use (Blei, 2012). Topic modeling algorithms are inference algorithms; they uncover a set of patterns that pervade a collection and represent each document according to how it exhibits them. These patterns tend to be thematically coherent, which is why the models are called “topic models.” Topic models are used for both descriptive tasks, such as to build thematic navigators of large collections of documents, and for predictive tasks, such as to aid document classification. Topic models have been extended and applied in many domains</p>
<p><a class="reference external" href="./LatentDirichletAllocation.rst">Latent Dirichlet Allocation (LDA)</a> is the simplest topic model, LDA is a generative probabilistic model for collections of discrete data such as text corpora.</p>
<div class="section" id="large-scale-learning">
<h3>Large-scale learning<a class="headerlink" href="#large-scale-learning" title="Permalink to this headline">¶</a></h3>
<p>Modern data analysis requires computation with massive data. These problems illustrate some of the challenges to modern data analysis. Our data are complex and high-dimensional; we have assumptions to make from science, intuition, or other data analyses that involve structures we believe exist in the data but that we cannot directly observe; and finally, our data sets are large, possibly even arriving in a never-ending stream. We deploy this library to computing with graphical models that are appropriate for massive datasets, data that might not fit in memory or even be stored locally. This is an efficient tool for learning LDA at large scales</p>
</div>
<div class="section" id="learning-methods-for-lda">
<h3>Learning methods for LDA<a class="headerlink" href="#learning-methods-for-lda" title="Permalink to this headline">¶</a></h3>
<p>To learn LDA at large-scale, a good and efficient approach is stochastic learning (online/streaming methods). The learning process includes 2 main steps:</p>
<ul class="simple">
<li>Inference for individual document: infer to find out the <strong>hidden local variables</strong>: topic proportion <span class="math">\(\theta\)</span> or topic indices <strong>z</strong>. To deal with this, we can estimate directly or estimate their distribution P(<span class="math">\(\theta\)</span> | <span class="math">\(\gamma\)</span>), P(<strong>z</strong> | <span class="math">\(\phi\)</span>) (<span class="math">\(\gamma\)</span>, <span class="math">\(phi\)</span> called “variational parameters”).</li>
<li>Update <strong>global variable</strong> in a stochastic way to find out directly topics <span class="math">\(\beta\)</span> or we can estimate topics by finding out its distribution P(<span class="math">\(\beta\)</span> | <span class="math">\(\lambda\)</span>) (estimating variational parameter <span class="math">\(\lambda\)</span>). Global variable here maybe <span class="math">\(\beta\)</span> or <span class="math">\(\lambda\)</span> depend on each stochastic methods.</li>
</ul>
<p>Indeed, this phase is as same as training step in machine learning.</p>
</div>
</div>
</div>
<div class="section" id="corpus">
<h1>Corpus<a class="headerlink" href="#corpus" title="Permalink to this headline">¶</a></h1>
<p>A corpus is a collection of digital documents. This collection is the input to topicmodel-lib from which it will infer the structure of the documents, their topics, topic proportions, etc. The latent structure inferred from the corpus can later be used to assign topics to new documents which were not present in the training corpus. For this reason, we also refer to this collection as the training corpus. No human intervention (such as tagging the documents by hand) is required - the topic classification is unsupervised.</p>
<div class="section" id="data-format">
<h2>Data Format<a class="headerlink" href="#data-format" title="Permalink to this headline">¶</a></h2>
<p>Because we need to learn the model from the massive data, the loading whole of training data into memory is a bad idea. Corpus used for training should be stored in a file and with a specific format. Our library supports 3 formats of data:</p>
<div class="section" id="raw-text">
<h3>Raw Text<a class="headerlink" href="#raw-text" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">raw_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Human machine interface for lab abc computer applications&quot;</span><span class="p">,</span>
              <span class="s2">&quot;A survey of user opinion of computer system response time&quot;</span><span class="p">,</span>
              <span class="s2">&quot;The EPS user interface management system&quot;</span><span class="p">,</span>
              <span class="s2">&quot;System and human system engineering testing of EPS&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Relation of user perceived response time to error measurement&quot;</span><span class="p">,</span>
              <span class="s2">&quot;The generation of random binary unordered trees&quot;</span><span class="p">,</span>
              <span class="s2">&quot;The intersection graph of paths in trees&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Graph minors IV Widths of trees and well quasi ordering&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Graph minors A survey&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>The raw corpus must be stored in a file. Each document is placed in 2 pair tag &lt;DOC&gt;&lt;/DOC&gt; and &lt;TEXT&gt;&lt;/TEXT&gt; as follow</p>
<img alt="_images/format1.PNG" src="_images/format1.PNG" />
<p>You can see <a class="reference external" href="https://github.com/TruongKhang/documentation/blob/master/examples/ap/data/ap_infer_raw.txt">raw AP corpus</a> for example</p>
</div>
<div class="section" id="term-frequency-tf">
<h3>Term-frequency (tf)<a class="headerlink" href="#term-frequency-tf" title="Permalink to this headline">¶</a></h3>
<p>Term-frequency format (<strong>tf</strong>) is derived from <a class="reference external" href="http://www.cs.columbia.edu/~blei/lda-c/">Blei, 2003</a>. This is a corpus which we achieve after preprocessing raw corpus. We also extract to a vocabulary set for that corpus (unique terms in whole corpus)</p>
<p>Under LDA, the words of each document are assumed exchangeable.  Thus, each document is succinctly represented as a sparse vector of word counts. The data is a file where each line is of the form:</p>
<p><cite>[N] [term_1]:[count] [term_2]:[count] …  [term_N]:[count]</cite></p>
<p>where [N] is the number of unique terms in the document, and the [count] associated with each term is how many times that term appeared in the document.  Note that [term_i] is an integer which indexes the term (index of that term in file vocabulary); it is not a string.</p>
<p>For example, with corpus as raw_corpus above and file vocabulary is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mf">0.</span> <span class="s2">&quot;human&quot;</span>
<span class="mf">1.</span> <span class="s2">&quot;machine&quot;</span>
<span class="mf">2.</span> <span class="s2">&quot;interface&quot;</span>
<span class="mf">3.</span> <span class="s2">&quot;lab&quot;</span>
<span class="mf">4.</span> <span class="s2">&quot;abc&quot;</span>
<span class="mf">5.</span> <span class="s2">&quot;computer&quot;</span>
<span class="mf">6.</span> <span class="s2">&quot;applications&quot;</span>
<span class="mf">7.</span> <span class="s2">&quot;survey&quot;</span>
<span class="mf">8.</span> <span class="s2">&quot;user&quot;</span>
<span class="mf">9.</span> <span class="s2">&quot;opinion&quot;</span>
<span class="mf">10.</span> <span class="s2">&quot;system&quot;</span>
<span class="mf">11.</span> <span class="s2">&quot;response&quot;</span>
<span class="mf">12.</span> <span class="s2">&quot;time&quot;</span>
<span class="mf">13.</span> <span class="s2">&quot;eps&quot;</span>
<span class="mf">14.</span> <span class="s2">&quot;management&quot;</span>
<span class="mf">15.</span> <span class="s2">&quot;engineering&quot;</span>
<span class="mf">16.</span> <span class="s2">&quot;testing&quot;</span>
<span class="mf">17.</span> <span class="s2">&quot;relation&quot;</span>
<span class="mf">18.</span> <span class="s2">&quot;perceived&quot;</span>
<span class="mf">19.</span> <span class="s2">&quot;error&quot;</span>
<span class="mf">20.</span> <span class="s2">&quot;measurement&quot;</span>
<span class="mf">21.</span> <span class="s2">&quot;generation&quot;</span>
<span class="mf">22.</span> <span class="s2">&quot;random&quot;</span>
<span class="mf">23.</span> <span class="s2">&quot;binary&quot;</span>
<span class="mf">24.</span> <span class="s2">&quot;unordered&quot;</span>
<span class="mf">25.</span> <span class="s2">&quot;trees&quot;</span>
<span class="mf">26.</span> <span class="s2">&quot;intersection&quot;</span>
<span class="mf">27.</span> <span class="s2">&quot;graph&quot;</span>
<span class="mf">28.</span> <span class="s2">&quot;paths&quot;</span>
<span class="mf">29.</span> <span class="s2">&quot;minors&quot;</span>
<span class="mf">30.</span> <span class="s2">&quot;widths&quot;</span>
<span class="mf">31.</span> <span class="s2">&quot;quasi&quot;</span>
<span class="mf">32.</span> <span class="s2">&quot;ordering&quot;</span>
</pre></div>
</div>
<p>The <strong>tf</strong> format of corpus will be:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">7</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span> <span class="mi">1</span><span class="p">:</span><span class="mi">1</span> <span class="mi">2</span><span class="p">:</span><span class="mi">1</span> <span class="mi">3</span><span class="p">:</span><span class="mi">1</span> <span class="mi">4</span><span class="p">:</span><span class="mi">1</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span> <span class="mi">6</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">7</span> <span class="mi">7</span><span class="p">:</span><span class="mi">1</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span> <span class="mi">9</span><span class="p">:</span><span class="mi">1</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span> <span class="mi">10</span><span class="p">:</span><span class="mi">1</span> <span class="mi">11</span><span class="p">:</span><span class="mi">1</span> <span class="mi">12</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">5</span> <span class="mi">13</span><span class="p">:</span><span class="mi">1</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span> <span class="mi">2</span><span class="p">:</span><span class="mi">1</span> <span class="mi">14</span><span class="p">:</span><span class="mi">1</span> <span class="mi">10</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">5</span> <span class="mi">10</span><span class="p">:</span><span class="mi">2</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span> <span class="mi">15</span><span class="p">:</span><span class="mi">1</span> <span class="mi">16</span><span class="p">:</span><span class="mi">1</span> <span class="mi">13</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">7</span> <span class="mi">17</span><span class="p">:</span><span class="mi">1</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span> <span class="mi">18</span><span class="p">:</span><span class="mi">1</span> <span class="mi">11</span><span class="p">:</span><span class="mi">1</span> <span class="mi">12</span><span class="p">:</span><span class="mi">1</span> <span class="mi">19</span><span class="p">:</span><span class="mi">1</span> <span class="mi">20</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">5</span> <span class="mi">21</span><span class="p">:</span><span class="mi">1</span> <span class="mi">22</span><span class="p">:</span><span class="mi">1</span> <span class="mi">23</span><span class="p">:</span><span class="mi">1</span> <span class="mi">24</span><span class="p">:</span><span class="mi">1</span> <span class="mi">25</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">4</span> <span class="mi">26</span><span class="p">:</span><span class="mi">1</span> <span class="mi">27</span><span class="p">:</span><span class="mi">1</span> <span class="mi">28</span><span class="p">:</span><span class="mi">1</span> <span class="mi">25</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">6</span> <span class="mi">27</span><span class="p">:</span><span class="mi">1</span> <span class="mi">29</span><span class="p">:</span><span class="mi">1</span> <span class="mi">30</span><span class="p">:</span><span class="mi">1</span> <span class="mi">25</span><span class="p">:</span><span class="mi">1</span> <span class="mi">31</span><span class="p">:</span><span class="mi">1</span> <span class="mi">32</span><span class="p">:</span><span class="mi">1</span>
<span class="mi">3</span> <span class="mi">27</span><span class="p">:</span><span class="mi">1</span> <span class="mi">29</span><span class="p">:</span><span class="mi">1</span> <span class="mi">7</span><span class="p">:</span><span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="term-sequence-sq">
<h3>Term-sequence (sq)<a class="headerlink" href="#term-sequence-sq" title="Permalink to this headline">¶</a></h3>
<p>Each document is represented by a sequence of token as follow</p>
<p><cite>[token_1] [token_2] [token_3]….</cite></p>
<p>[token_i] also is index of that token in vocabulary file, not a string. (maybe exist that [token_i] = [token_j])
The <strong>sq</strong> format of the corpus above will be:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span>
<span class="mi">7</span> <span class="mi">8</span> <span class="mi">9</span> <span class="mi">5</span> <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span>
<span class="mi">13</span> <span class="mi">8</span> <span class="mi">2</span> <span class="mi">14</span> <span class="mi">10</span>
<span class="mi">10</span> <span class="mi">0</span> <span class="mi">10</span> <span class="mi">15</span> <span class="mi">16</span> <span class="mi">13</span>
<span class="mi">17</span> <span class="mi">8</span> <span class="mi">18</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">19</span> <span class="mi">20</span>
<span class="mi">21</span> <span class="mi">22</span> <span class="mi">23</span> <span class="mi">24</span> <span class="mi">25</span>
<span class="mi">26</span> <span class="mi">27</span> <span class="mi">28</span> <span class="mi">25</span>
<span class="mi">27</span> <span class="mi">29</span> <span class="mi">30</span> <span class="mi">25</span> <span class="mi">31</span> <span class="mi">32</span>
<span class="mi">27</span> <span class="mi">29</span> <span class="mi">7</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="guide-to-learn-model">
<h1>Guide to learn model<a class="headerlink" href="#guide-to-learn-model" title="Permalink to this headline">¶</a></h1>
<p>In this phase, the main task is to find out the global variable (topics) - in this project, we call it named <cite>model</cite> for simple. We designed the state-of-the-art methods (online/streaming learning): <a class="reference external" href="./methods/online_vb.rst">Online VB</a>, <a class="reference external" href="./methods/online_cvb0.rst">Online CVB0</a>, <a class="reference external" href="./methods/online_cgs.rst">Online CGS</a>, <a class="reference external" href="./methods/online_ope.rst">Online OPE</a>, <a class="reference external" href="./methods/online_fw.rst">Online FW</a>, <a class="reference external" href="./methods/streaming_vb.rst">Streaming VB</a>, <a class="reference external" href="./methods/streaming_ope.rst">Streaming OPE</a>, <a class="reference external" href="./methods/streaming_fw.rst">Streaming FW</a>, <a class="reference external" href="./methods/ml_ope.rst">ML-OPE</a>, <a class="reference external" href="./methods/ml_cgs.rst">ML-CGS</a>, <a class="reference external" href="./methods/ml_fw.rst">ML-FW</a></p>
<p>All of this methods are used in the same way. So, in this guide, we’ll demo with a specific method such as Online VB. This method is proposed by Hoffman-2010, using stochastic variational inference</p>
<div class="section" id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h2>
<p>Make sure that your training data must be stored in a text file and abide by the <a class="reference internal" href="#data-format">Data Format</a>: <strong>tf</strong>, <strong>sq</strong> or <strong>raw text</strong></p>
<p>We also support the <a class="reference external" href="./preprocessing.rst">preprocessing</a> module to work with the raw text format, you can convert to the tf or sq format. But if you don’t want to use it, it’s OK because we integrated that work in class <code class="docutils literal"><span class="pre">DataSet</span></code>. Therefore, the first thing you need to do is create an object <code class="docutils literal"><span class="pre">DataSet</span></code></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tmlib.datasets</span> <span class="k">import</span> <span class="n">DataSet</span>
<span class="c1"># data_path is the path of file contains your training data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle_every</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>The statement above is used when <cite>data_path</cite> is the raw text format. If your training file is the tf or sq format. You need to add an argument is the vocabulary file of the corpus as follow:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># vocab_file is the path of file vocabulary of corpus</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle_every</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The parameters <strong>batch_size</strong>, <strong>passes</strong>, <strong>shuffle_every</strong> you can see in <a class="reference external" href="./methods/online_vb.rst">documentation here</a></p>
</div>
<div class="section" id="learning">
<h2>Learning<a class="headerlink" href="#learning" title="Permalink to this headline">¶</a></h2>
<p>First, we need to create an object <code class="docutils literal"><span class="pre">OnlineVB</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tmlib.lda</span> <span class="k">import</span> <span class="n">OnlineVB</span>
<span class="n">onl_vb</span> <span class="o">=</span> <span class="n">OnlineVB</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">tau0</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal"><span class="pre">data</span></code> is the object which created above. Parameter <strong>num_topics</strong> number of requested latent topics to be extracted from the training corpus. <strong>alpha</strong>, <strong>eta</strong> are hyperparameters of LDA model that affect sparsity of the topic proportions (<span class="math">\(\theta\)</span>) and topic-word (<span class="math">\(\beta\)</span>) distributions. <strong>tau0</strong>, <strong>kappa</strong> are learning parameters which are used in the update global variable step (same meaning as learning rate in the gradient descent optimization)</p>
<p>Start learning by call function <strong>learn_model</strong>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">onl_vb</span><span class="o">.</span><span class="n">learn_model</span><span class="p">()</span>
</pre></div>
</div>
<p>The returned result is an object <a class="reference external" href="./ldamodel.rst">LdaModel</a></p>
<p>You can also save the model (<span class="math">\(\beta\)</span> or <span class="math">\(\lambda\)</span>) or some statistics such as: learning time, sparsity of document in the learning process</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">onl_vb</span><span class="o">.</span><span class="n">learn_model</span><span class="p">(</span><span class="n">save_statistic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_model_every</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">compute_sparsity_every</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">save_top_words_every</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_top_words</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">model_folder</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The result is saved in folder <cite>models</cite>. More detail about this parameters, read <a class="reference external" href="./methods/online_vb.rst">here</a></p>
<p>One more thing, the topic proportions (<span class="math">\(\theta\)</span>) of each document in the corpus can be saved in a file <code class="docutils literal"><span class="pre">.h5</span></code>. This work is necessary for <a class="reference external" href="./visualization.rst">visualization</a> module but it’ll make the learning time slower. So, be careful when using it!</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># for example: path_of_h5_file = &#39;models/database.h5&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">onl_vb</span><span class="o">.</span><span class="n">learn_model</span><span class="p">(</span><span class="n">save_topic_proportion</span><span class="o">=</span><span class="n">path_of_h5_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="saving-model-display-topics">
<h2>Saving model, display topics<a class="headerlink" href="#saving-model-display-topics" title="Permalink to this headline">¶</a></h2>
<p>After the learning phase as above, you can save the topic distribution (<cite>model</cite> - <span class="math">\(\beta\)</span> or <span class="math">\(\lambda\)</span>)</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># path_to_save is the path of file to save model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">path_to_save</span><span class="p">,</span> <span class="n">file_type</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>File <cite>path_to_save</cite> is the <code class="docutils literal"><span class="pre">.npy</span></code> file if type of file is binary or is the <code class="docutils literal"><span class="pre">.txt</span></code> file if <strong>file_type</strong> is <code class="docutils literal"><span class="pre">'txt'</span></code></p>
<p>You also can display the topics discovered</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># display topics, print the top 10 words of each topic to screen</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_top_words</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">display_result</span><span class="o">=</span><span class="s1">&#39;screen&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you want to save in a file:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># path_file is to which data is saved</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_top_words</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">display_result</span><span class="o">=</span><span class="n">path_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="inference-for-new-documents">
<h1>Inference for new documents<a class="headerlink" href="#inference-for-new-documents" title="Permalink to this headline">¶</a></h1>
<p>After learning phase, you have the <cite>model</cite> - topic distributions (<span class="math">\(\beta\)</span> or <span class="math">\(\lambda\)</span>). You want to infer for some documents to find out what topics these documents are related to. We need to estimate topic-proportions <span class="math">\(\theta\)</span></p>
<p>First, create an object <code class="docutils literal"><span class="pre">DataSet</span></code> to load new documents from a file.</p>
<p>If data format in that file is <a class="reference internal" href="#raw-text">Raw Text</a>, you need the vocabulary file used in learning phase</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tmlib.datasets</span> <span class="k">import</span> <span class="n">DataSet</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">()</span>
<span class="c1"># vocab_file is the vocabulary file used in learning phase</span>
<span class="n">new_corpus</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">load_new_documents</span><span class="p">(</span><span class="n">file_new_docs</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">)</span>
</pre></div>
</div>
<p>or if data format is the <strong>tf</strong> or <strong>sq</strong> format. The statement simply is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">new_corpus</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">load_new_documents</span><span class="p">(</span><span class="n">file_new_docs</span><span class="p">)</span>
</pre></div>
</div>
<p>After that, you have to load the model which is saved in the learning phase into object <code class="docutils literal"><span class="pre">OnlineVB</span></code></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># create object LdaModel</span>
<span class="n">learnt_model</span> <span class="o">=</span> <span class="n">LdaModel</span><span class="p">()</span>
<span class="c1"># read topic distribution from file</span>
<span class="n">lda_model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">path_file_to_read</span><span class="p">)</span>

<span class="c1"># load lda_model into OnlineVB</span>
<span class="kn">from</span> <span class="nn">tmlib.lda</span> <span class="k">import</span> <span class="n">OnlineVB</span>
<span class="n">online_vb</span> <span class="o">=</span> <span class="n">OnlineVB</span><span class="p">(</span><span class="n">lda_model</span><span class="o">=</span><span class="n">learnt_model</span><span class="p">)</span>
</pre></div>
</div>
<p>Call <code class="docutils literal"><span class="pre">infer_new_docs</span></code> function to rum inference</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">gamma</span> <span class="o">=</span> <span class="n">online_vb</span><span class="o">.</span><span class="n">infer_new_docs</span><span class="p">(</span><span class="n">new_corpus</span><span class="p">)</span>
<span class="c1"># you can estimate topic proportion theta from variational parameter gamma</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">online_vb</span><span class="o">.</span><span class="n">estimate_topic_proportion</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example">
<h1>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h1>
<p>You can see in <a class="reference external" href="https://github.com/hncuong/topicmodel-lib/tree/master/examples/ap">example folder</a>. We prepared the AP corpus including both raw corpus and term-frequency corpus. In here, we’ll show code with both of type corpus and use method <a class="reference external" href="./methods/online_ope.rst">Online OPE</a> (known is fast than Online VB)</p>
<ul>
<li><p class="first">Raw AP corpus</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tmlib.lda</span> <span class="k">import</span> <span class="n">OnlineOPE</span>
<span class="kn">from</span> <span class="nn">tmlib.datasets</span> <span class="k">import</span> <span class="n">DataSet</span>

<span class="c1"># data preparation</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="s1">&#39;data/ap_train_raw.txt&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle_every</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># learning</span>
<span class="n">onl_ope</span> <span class="o">=</span> <span class="n">OnlineOPE</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">onl_vb</span><span class="o">.</span><span class="n">learn_model</span><span class="p">()</span>
<span class="c1"># save model (beta or lambda)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">&#39;topic_distribution.npy&#39;</span><span class="p">)</span>
<span class="c1"># display top 10 words of each topic</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_top_words</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">display_result</span><span class="o">=</span><span class="s1">&#39;screen&#39;</span><span class="p">)</span>

<span class="c1"># inference for new documents</span>
<span class="n">vocab_file</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab_file</span>
<span class="n">new_corpus</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">load_new_documents</span><span class="p">(</span><span class="s1">&#39;data/ap_infer_raw.txt&#39;</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">)</span>
<span class="n">topic_proportions</span> <span class="o">=</span> <span class="n">onl_ope</span><span class="o">.</span><span class="n">infer_new_docs</span><span class="p">(</span><span class="n">new_corpus</span><span class="p">)</span>
</pre></div>
</div>
<p>Topics:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">topic</span> <span class="mi">0</span><span class="p">:</span> <span class="n">water</span><span class="p">,</span> <span class="n">environmental</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">trust</span><span class="p">,</span> <span class="n">earth</span><span class="p">,</span> <span class="n">pollution</span><span class="p">,</span> <span class="n">taxes</span><span class="p">,</span> <span class="n">claims</span><span class="p">,</span> <span class="n">air</span><span class="p">,</span> <span class="n">boat</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">1</span><span class="p">:</span> <span class="n">year</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">years</span><span class="p">,</span> <span class="n">mrs</span><span class="p">,</span> <span class="n">police</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">day</span><span class="p">,</span> <span class="n">family</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">women</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">2</span><span class="p">:</span> <span class="n">percent</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">company</span><span class="p">,</span> <span class="n">department</span><span class="p">,</span> <span class="n">million</span><span class="p">,</span> <span class="n">plant</span><span class="p">,</span> <span class="n">health</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">report</span><span class="p">,</span> <span class="n">study</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">3</span><span class="p">:</span> <span class="n">police</span><span class="p">,</span> <span class="n">government</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">military</span><span class="p">,</span> <span class="n">iraq</span><span class="p">,</span> <span class="n">army</span><span class="p">,</span> <span class="n">killed</span><span class="p">,</span> <span class="n">officials</span><span class="p">,</span> <span class="n">israel</span><span class="p">,</span> <span class="n">war</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">4</span><span class="p">:</span> <span class="n">cent</span><span class="p">,</span> <span class="n">cents</span><span class="p">,</span> <span class="n">weather</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">temperatures</span><span class="p">,</span> <span class="n">bushel</span><span class="p">,</span> <span class="n">snow</span><span class="p">,</span> <span class="n">inches</span><span class="p">,</span> <span class="n">coast</span><span class="p">,</span> <span class="n">central</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">5</span><span class="p">:</span> <span class="n">billion</span><span class="p">,</span> <span class="n">deficit</span><span class="p">,</span> <span class="n">housing</span><span class="p">,</span> <span class="n">japan</span><span class="p">,</span> <span class="n">japanese</span><span class="p">,</span> <span class="n">trade</span><span class="p">,</span> <span class="n">fair</span><span class="p">,</span> <span class="n">cuba</span><span class="p">,</span> <span class="n">imports</span><span class="p">,</span> <span class="n">exports</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">6</span><span class="p">:</span> <span class="n">cbs</span><span class="p">,</span> <span class="n">abc</span><span class="p">,</span> <span class="n">williams</span><span class="p">,</span> <span class="n">miles</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">earthquake</span><span class="p">,</span> <span class="n">quake</span><span class="p">,</span> <span class="n">homeless</span><span class="p">,</span> <span class="n">pope</span><span class="p">,</span> <span class="n">john</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">7</span><span class="p">:</span> <span class="n">bush</span><span class="p">,</span> <span class="n">president</span><span class="p">,</span> <span class="n">dukakis</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">reagan</span><span class="p">,</span> <span class="n">congress</span><span class="p">,</span> <span class="n">campaign</span><span class="p">,</span> <span class="n">house</span><span class="p">,</span> <span class="n">united</span><span class="p">,</span> <span class="n">south</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">8</span><span class="p">:</span> <span class="n">campaign</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">northern</span><span class="p">,</span> <span class="n">mexico</span><span class="p">,</span> <span class="n">republican</span><span class="p">,</span> <span class="n">police</span><span class="p">,</span> <span class="n">county</span><span class="p">,</span> <span class="n">alabama</span><span class="p">,</span> <span class="n">cuomo</span><span class="p">,</span> <span class="n">governor</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">9</span><span class="p">:</span> <span class="n">trade</span><span class="p">,</span> <span class="n">takeshita</span><span class="p">,</span> <span class="n">deconcini</span><span class="p">,</span> <span class="n">oil</span><span class="p">,</span> <span class="n">pension</span><span class="p">,</span> <span class="n">committee</span><span class="p">,</span> <span class="n">keating</span><span class="p">,</span> <span class="n">fernandez</span><span class="p">,</span> <span class="n">lawsuit</span><span class="p">,</span> <span class="n">illness</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">10</span><span class="p">:</span> <span class="n">court</span><span class="p">,</span> <span class="n">case</span><span class="p">,</span> <span class="n">attorney</span><span class="p">,</span> <span class="n">trial</span><span class="p">,</span> <span class="n">judge</span><span class="p">,</span> <span class="n">federal</span><span class="p">,</span> <span class="n">charges</span><span class="p">,</span> <span class="n">law</span><span class="p">,</span> <span class="n">justice</span><span class="p">,</span> <span class="n">jury</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">11</span><span class="p">:</span> <span class="n">party</span><span class="p">,</span> <span class="n">government</span><span class="p">,</span> <span class="n">political</span><span class="p">,</span> <span class="n">workers</span><span class="p">,</span> <span class="n">national</span><span class="p">,</span> <span class="n">labor</span><span class="p">,</span> <span class="n">opposition</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">elections</span><span class="p">,</span> <span class="n">country</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">12</span><span class="p">:</span> <span class="n">million</span><span class="p">,</span> <span class="n">tax</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">income</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">cash</span><span class="p">,</span> <span class="n">estate</span><span class="p">,</span> <span class="n">assets</span><span class="p">,</span> <span class="n">money</span><span class="p">,</span> <span class="n">billion</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">13</span><span class="p">:</span> <span class="n">school</span><span class="p">,</span> <span class="n">movie</span><span class="p">,</span> <span class="n">film</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">ban</span><span class="p">,</span> <span class="n">mca</span><span class="p">,</span> <span class="n">theater</span><span class="p">,</span> <span class="n">roberts</span><span class="p">,</span> <span class="n">fees</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">14</span><span class="p">:</span> <span class="n">students</span><span class="p">,</span> <span class="n">computer</span><span class="p">,</span> <span class="n">farmers</span><span class="p">,</span> <span class="n">teachers</span><span class="p">,</span> <span class="n">smoking</span><span class="p">,</span> <span class="n">schools</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">stolen</span><span class="p">,</span> <span class="n">kasparov</span><span class="p">,</span> <span class="n">faculty</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">15</span><span class="p">:</span> <span class="n">dollar</span><span class="p">,</span> <span class="n">yen</span><span class="p">,</span> <span class="n">late</span><span class="p">,</span> <span class="n">gold</span><span class="p">,</span> <span class="n">london</span><span class="p">,</span> <span class="n">bid</span><span class="p">,</span> <span class="n">ounce</span><span class="p">,</span> <span class="n">bank</span><span class="p">,</span> <span class="n">thursday</span><span class="p">,</span> <span class="n">dealers</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">16</span><span class="p">:</span> <span class="n">percent</span><span class="p">,</span> <span class="n">market</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">stock</span><span class="p">,</span> <span class="n">million</span><span class="p">,</span> <span class="n">prices</span><span class="p">,</span> <span class="n">billion</span><span class="p">,</span> <span class="n">rose</span><span class="p">,</span> <span class="n">exchange</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">17</span><span class="p">:</span> <span class="n">soviet</span><span class="p">,</span> <span class="n">gorbachev</span><span class="p">,</span> <span class="n">united</span><span class="p">,</span> <span class="n">union</span><span class="p">,</span> <span class="n">president</span><span class="p">,</span> <span class="n">officials</span><span class="p">,</span> <span class="n">west</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">germany</span><span class="p">,</span> <span class="n">east</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">18</span><span class="p">:</span> <span class="n">bill</span><span class="p">,</span> <span class="n">senate</span><span class="p">,</span> <span class="n">house</span><span class="p">,</span> <span class="n">kennedy</span><span class="p">,</span> <span class="n">sen</span><span class="p">,</span> <span class="n">rep</span><span class="p">,</span> <span class="n">measure</span><span class="p">,</span> <span class="n">humphrey</span><span class="p">,</span> <span class="n">director</span><span class="p">,</span> <span class="n">thompson</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">19</span><span class="p">:</span> <span class="n">meese</span><span class="p">,</span> <span class="n">museum</span><span class="p">,</span> <span class="n">disney</span><span class="p">,</span> <span class="n">school</span><span class="p">,</span> <span class="n">city</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">art</span><span class="p">,</span> <span class="n">smith</span><span class="p">,</span> <span class="n">buildings</span><span class="p">,</span> <span class="n">memorial</span><span class="p">,</span>
</pre></div>
</div>
</li>
<li><p class="first">tf format</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tmlib.lda</span> <span class="k">import</span> <span class="n">OnlineOPE</span>
<span class="kn">from</span> <span class="nn">tmlib.datasets</span> <span class="k">import</span> <span class="n">DataSet</span>

<span class="c1"># data preparation</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="s1">&#39;data/ap_train.txt&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle_every</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="s1">&#39;data/vocab.txt&#39;</span><span class="p">)</span>
<span class="c1"># learning</span>
<span class="n">onl_ope</span> <span class="o">=</span> <span class="n">OnlineOPE</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">onl_vb</span><span class="o">.</span><span class="n">learn_model</span><span class="p">()</span>
<span class="c1"># save model (beta or lambda)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">&#39;topic_distribution.npy&#39;</span><span class="p">)</span>
<span class="c1"># display top 10 words of each topic</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_top_words</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">display_result</span><span class="o">=</span><span class="s1">&#39;screen&#39;</span><span class="p">)</span>

<span class="c1"># inference for new documents</span>
<span class="n">new_corpus</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">load_new_documents</span><span class="p">(</span><span class="s1">&#39;data/ap_infer.txt&#39;</span><span class="p">)</span>
<span class="n">topic_proportions</span> <span class="o">=</span> <span class="n">onl_ope</span><span class="o">.</span><span class="n">infer_new_docs</span><span class="p">(</span><span class="n">new_corpus</span><span class="p">)</span>
</pre></div>
</div>
<p>Topics:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">topic</span> <span class="mi">0</span><span class="p">:</span> <span class="n">two</span><span class="p">,</span> <span class="n">new</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">years</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">officials</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">fire</span><span class="p">,</span> <span class="n">day</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">1</span><span class="p">:</span> <span class="n">israel</span><span class="p">,</span> <span class="n">minister</span><span class="p">,</span> <span class="n">prime</span><span class="p">,</span> <span class="n">vietnam</span><span class="p">,</span> <span class="n">thatcher</span><span class="p">,</span> <span class="n">party</span><span class="p">,</span> <span class="n">opec</span><span class="p">,</span> <span class="n">ministers</span><span class="p">,</span> <span class="n">demjanjuk</span><span class="p">,</span> <span class="n">labor</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">2</span><span class="p">:</span> <span class="n">million</span><span class="p">,</span> <span class="n">percent</span><span class="p">,</span> <span class="n">futures</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">market</span><span class="p">,</span> <span class="n">bank</span><span class="p">,</span> <span class="n">analysts</span><span class="p">,</span> <span class="n">new</span><span class="p">,</span> <span class="n">cbs</span><span class="p">,</span> <span class="n">nbc</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">3</span><span class="p">:</span> <span class="n">dukakis</span><span class="p">,</span> <span class="n">jackson</span><span class="p">,</span> <span class="n">democratic</span><span class="p">,</span> <span class="n">presidential</span><span class="p">,</span> <span class="n">campaign</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">vote</span><span class="p">,</span> <span class="n">voters</span><span class="p">,</span> <span class="n">delegates</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">4</span><span class="p">:</span> <span class="n">million</span><span class="p">,</span> <span class="n">company</span><span class="p">,</span> <span class="n">new</span><span class="p">,</span> <span class="n">billion</span><span class="p">,</span> <span class="n">inc</span><span class="p">,</span> <span class="n">corp</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">court</span><span class="p">,</span> <span class="n">federal</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">5</span><span class="p">:</span> <span class="n">bush</span><span class="p">,</span> <span class="n">united</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">president</span><span class="p">,</span> <span class="n">trade</span><span class="p">,</span> <span class="n">billion</span><span class="p">,</span> <span class="n">house</span><span class="p">,</span> <span class="n">congress</span><span class="p">,</span> <span class="n">new</span><span class="p">,</span> <span class="n">budget</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">6</span><span class="p">:</span> <span class="n">stock</span><span class="p">,</span> <span class="n">market</span><span class="p">,</span> <span class="n">dollar</span><span class="p">,</span> <span class="n">trading</span><span class="p">,</span> <span class="n">exchange</span><span class="p">,</span> <span class="n">yen</span><span class="p">,</span> <span class="n">prices</span><span class="p">,</span> <span class="n">late</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">rose</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">7</span><span class="p">:</span> <span class="n">korean</span><span class="p">,</span> <span class="n">korea</span><span class="p">,</span> <span class="n">city</span><span class="p">,</span> <span class="n">village</span><span class="p">,</span> <span class="n">police</span><span class="p">,</span> <span class="n">north</span><span class="p">,</span> <span class="n">st</span><span class="p">,</span> <span class="n">traffic</span><span class="p">,</span> <span class="n">koreas</span><span class="p">,</span> <span class="n">citys</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">8</span><span class="p">:</span> <span class="n">police</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">killed</span><span class="p">,</span> <span class="n">two</span><span class="p">,</span> <span class="n">government</span><span class="p">,</span> <span class="n">army</span><span class="p">,</span> <span class="n">military</span><span class="p">,</span> <span class="n">officials</span><span class="p">,</span> <span class="n">three</span><span class="p">,</span> <span class="n">city</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">9</span><span class="p">:</span> <span class="n">south</span><span class="p">,</span> <span class="n">africa</span><span class="p">,</span> <span class="n">african</span><span class="p">,</span> <span class="n">black</span><span class="p">,</span> <span class="n">elections</span><span class="p">,</span> <span class="n">party</span><span class="p">,</span> <span class="n">national</span><span class="p">,</span> <span class="n">war</span><span class="p">,</span> <span class="n">mandela</span><span class="p">,</span> <span class="n">blacks</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">10</span><span class="p">:</span> <span class="n">states</span><span class="p">,</span> <span class="n">united</span><span class="p">,</span> <span class="n">nicaragua</span><span class="p">,</span> <span class="n">noriega</span><span class="p">,</span> <span class="n">drug</span><span class="p">,</span> <span class="n">contras</span><span class="p">,</span> <span class="n">court</span><span class="p">,</span> <span class="n">coup</span><span class="p">,</span> <span class="n">humphrey</span><span class="p">,</span> <span class="n">manila</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">11</span><span class="p">:</span> <span class="n">reagan</span><span class="p">,</span> <span class="n">china</span><span class="p">,</span> <span class="n">nuclear</span><span class="p">,</span> <span class="n">study</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">prisoners</span><span class="p">,</span> <span class="n">fitzwater</span><span class="p">,</span> <span class="n">researchers</span><span class="p">,</span> <span class="n">games</span><span class="p">,</span> <span class="n">animals</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">12</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="n">new</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">years</span><span class="p">,</span> <span class="n">percent</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">two</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">13</span><span class="p">:</span> <span class="n">trial</span><span class="p">,</span> <span class="n">case</span><span class="p">,</span> <span class="n">prison</span><span class="p">,</span> <span class="n">charges</span><span class="p">,</span> <span class="n">convicted</span><span class="p">,</span> <span class="n">jury</span><span class="p">,</span> <span class="n">attorney</span><span class="p">,</span> <span class="n">guilty</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">prosecutors</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">14</span><span class="p">:</span> <span class="n">rain</span><span class="p">,</span> <span class="n">northern</span><span class="p">,</span> <span class="n">texas</span><span class="p">,</span> <span class="n">inches</span><span class="p">,</span> <span class="n">california</span><span class="p">,</span> <span class="n">central</span><span class="p">,</span> <span class="n">damage</span><span class="p">,</span> <span class="n">santa</span><span class="p">,</span> <span class="n">hospital</span><span class="p">,</span> <span class="n">valley</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">15</span><span class="p">:</span> <span class="n">soviet</span><span class="p">,</span> <span class="n">government</span><span class="p">,</span> <span class="n">gorbachev</span><span class="p">,</span> <span class="n">union</span><span class="p">,</span> <span class="n">party</span><span class="p">,</span> <span class="n">president</span><span class="p">,</span> <span class="n">political</span><span class="p">,</span> <span class="n">two</span><span class="p">,</span> <span class="n">news</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">16</span><span class="p">:</span> <span class="n">service</span><span class="p">,</span> <span class="n">offer</span><span class="p">,</span> <span class="n">court</span><span class="p">,</span> <span class="n">companies</span><span class="p">,</span> <span class="n">firm</span><span class="p">,</span> <span class="n">ruling</span><span class="p">,</span> <span class="n">information</span><span class="p">,</span> <span class="n">appeals</span><span class="p">,</span> <span class="n">operations</span><span class="p">,</span> <span class="n">services</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">17</span><span class="p">:</span> <span class="n">water</span><span class="p">,</span> <span class="n">care</span><span class="p">,</span> <span class="n">homeless</span><span class="p">,</span> <span class="n">environmental</span><span class="p">,</span> <span class="n">pollution</span><span class="p">,</span> <span class="n">fair</span><span class="p">,</span> <span class="n">species</span><span class="p">,</span> <span class="n">air</span><span class="p">,</span> <span class="n">disaster</span><span class="p">,</span> <span class="n">farm</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">18</span><span class="p">:</span> <span class="n">percent</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">cents</span><span class="p">,</span> <span class="n">oil</span><span class="p">,</span> <span class="n">prices</span><span class="p">,</span> <span class="n">west</span><span class="p">,</span> <span class="n">german</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">price</span><span class="p">,</span>
<span class="n">topic</span> <span class="mi">19</span><span class="p">:</span> <span class="n">air</span><span class="p">,</span> <span class="n">plane</span><span class="p">,</span> <span class="n">flight</span><span class="p">,</span> <span class="n">two</span><span class="p">,</span> <span class="n">iraq</span><span class="p">,</span> <span class="n">soviet</span><span class="p">,</span> <span class="n">force</span><span class="p">,</span> <span class="n">kuwait</span><span class="p">,</span> <span class="n">airport</span><span class="p">,</span> <span class="n">iraqi</span><span class="p">,</span>
</pre></div>
</div>
</li>
</ul>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="lda_model.html" class="btn btn-neutral float-right" title="LDA Model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Welcome to topicmodel-lib’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, DSLab.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>